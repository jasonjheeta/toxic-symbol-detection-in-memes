{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the text is extracted from the unethical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text import CharErrorRate, WordErrorRate\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"memotion_dataset_7k/labels.csv\")\n",
    "image_names = df[\"image_name\"][:500].tolist()\n",
    "text = df[\"text_corrected\"][:500].tolist()\n",
    "wer = WordErrorRate()\n",
    "cer = CharErrorRate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for EasyOCR on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.37\n",
      "CER: 0.18\n",
      "The execution took 67.72 seconds\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2 as cv\n",
    "\n",
    "start_time = time.time()\n",
    "reader = easyocr.Reader([\"en\"])\n",
    "predictions = []\n",
    "\n",
    "for image_name in image_names:\n",
    "    image_path = \"memotion_dataset_7k/images/\" + image_name\n",
    "    image = cv.imread(image_path, 0)\n",
    "    result = \" \".join(reader.readtext(image, detail=0))\n",
    "    predictions.append(result)\n",
    "\n",
    "predictions = [prediction.lower() for prediction in predictions]\n",
    "text = [txt.lower() for txt in text]\n",
    "print(f\"WER: {round(wer(predictions, text).item(), 2)}\")\n",
    "print(f\"CER: {round(cer(predictions, text).item(), 2)}\")\n",
    "print(f\"The execution took {(time.time() - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for Tesseract OCR on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.64\n",
      "CER: 0.48\n",
      "The execution took 103.99 seconds\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import  cv2 as cv\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = []\n",
    "\n",
    "for image_name in image_names:\n",
    "    image_path = \"memotion_dataset_7k/images/\" + image_name\n",
    "    image = cv.imread(image_path, 0)\n",
    "    result = pytesseract.image_to_string(image, config=\"--oem 3 --psm 11\")\n",
    "    predictions.append(result)\n",
    "\n",
    "predictions = [prediction.lower() for prediction in predictions]\n",
    "text = [txt.lower() for txt in text]\n",
    "print(f\"WER: {round(wer(predictions, text).item(), 2)}\")\n",
    "print(f\"CER: {round(cer(predictions, text).item(), 2)}\")\n",
    "print(f\"The execution took {(time.time() - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for PaddleOCR on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/01/26 09:17:29] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/01/26 09:17:29] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/01/26 09:17:30] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.36\n",
      "CER: 0.15\n",
      "The execution took 31.11 seconds\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "start_time = time.time()\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"en\", show_log=False, ocr_version=\"PP-OCRv4\", use_space_char=True, use_dilation=True)\n",
    "predictions = []\n",
    "\n",
    "for image_name in image_names:\n",
    "    image_path = \"memotion_dataset_7k/images/\" + image_name\n",
    "    result = ocr.ocr(image_path, cls=False)\n",
    "    if result[0] != None:\n",
    "        result = \" \".join([line[1][0] for res in result for line in res])\n",
    "    else:\n",
    "        result = \"\"\n",
    "    predictions.append(result)\n",
    "\n",
    "predictions = [prediction.lower() for prediction in predictions]\n",
    "text = [txt.lower() for txt in text]\n",
    "print(f\"WER: {round(wer(predictions, text).item(), 2)}\")\n",
    "print(f\"CER: {round(cer(predictions, text).item(), 2)}\")\n",
    "print(f\"The execution took {(time.time() - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for GOT OCR on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.37\n",
      "CER: 0.16\n",
      "The execution took 728.33 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import logging\n",
    "\n",
    "start_time = time.time()\n",
    "logging.set_verbosity_error() \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ucaslcl/GOT-OCR2_0\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"ucaslcl/GOT-OCR2_0\", trust_remote_code=True, low_cpu_mem_usage=True, device_map=\"cuda\", use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
    "model = model.eval().cuda()\n",
    "predictions = []\n",
    "\n",
    "for image_name in image_names:\n",
    "    image_path = \"memotion_dataset_7k/images/\" + image_name\n",
    "    result = model.chat(tokenizer, image_path, ocr_type=\"ocr\")\n",
    "    predictions.append(result)\n",
    "\n",
    "predictions = [prediction.lower() for prediction in predictions]\n",
    "text = [txt.lower() for txt in text]\n",
    "print(f\"WER: {round(wer(predictions, text).item(), 2)}\")\n",
    "print(f\"CER: {round(cer(predictions, text).item(), 2)}\")\n",
    "print(f\"The execution took {(time.time() - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.16\n",
      "CER: 0.11\n",
      "The execution took 80.68 seconds\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "start_time = time.time()\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_name in image_names:\n",
    "    image_path = \"memotion_dataset_7k/images/\" + image_name\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        response = client.text_detection(image=image)\n",
    "\n",
    "        if response.error.message:\n",
    "            raise Exception(\n",
    "                \"{}\\nFor more info on error messages, check: \"\n",
    "                \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "            )\n",
    "        \n",
    "        texts = response.text_annotations\n",
    "        result = texts[0].description.replace(\"\\n\", \" \")\n",
    "        predictions.append(result)\n",
    "\n",
    "predictions = [prediction.lower() for prediction in predictions]\n",
    "text = [txt.lower() for txt in text]\n",
    "print(f\"WER: {round(wer(predictions, text).item(), 2)}\")\n",
    "print(f\"CER: {round(cer(predictions, text).item(), 2)}\")\n",
    "print(f\"The execution took {(time.time() - start_time):.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
