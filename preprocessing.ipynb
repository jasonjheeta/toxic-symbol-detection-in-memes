{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text is added to all memes and filter out any images that can't be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading OnToxMeme_dataset/combined_images/120.png\n",
      "Error reading OnToxMeme_dataset/combined_images/332.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading OnToxMeme_dataset/combined_images/285.png\n",
      "Error reading OnToxMeme_dataset/combined_images/316.png\n",
      "Error reading OnToxMeme_dataset/combined_images/61.png\n",
      "Error reading OnToxMeme_dataset/combined_images/64.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading OnToxMeme_dataset/combined_images/29.png\n",
      "Error reading OnToxMeme_dataset/combined_images/30.png\n",
      "Error reading OnToxMeme_dataset/combined_images/32.png\n",
      "Error reading OnToxMeme_dataset/combined_images/34.png\n",
      "Error reading OnToxMeme_dataset/combined_images/503.png\n",
      "Error reading OnToxMeme_dataset/combined_images/444.png\n"
     ]
    }
   ],
   "source": [
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import re\n",
    "from google.cloud import vision\n",
    "import json\n",
    "\n",
    "def extract_text(image_path):\n",
    "    try:\n",
    "        img = cv.imread(image_path)\n",
    "\n",
    "        if not img.size:\n",
    "            print(f'Error reading {image_path}')\n",
    "            return None\n",
    "\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "            image = vision.Image(content=content)\n",
    "\n",
    "            response = client.text_detection(image=image)\n",
    "            \n",
    "            if response.error.message:\n",
    "                raise Exception()\n",
    "\n",
    "            texts = response.text_annotations\n",
    "            text = texts[0].description.replace(\"\\n\", \" \")\n",
    "\n",
    "            if text != \"\":\n",
    "                text = re.sub(r\"^\\s*\\S+\\.[a-zA-Z]{3}\\s*|\\s*\\S+\\.[a-zA-Z]{3}\\s*$\", \"\", text)\n",
    "                text = re.sub(r\"\\s*\\S+\\.[a-zA-Z]{3}\\s*\", \" \", text)\n",
    "                text = re.sub(rf\"^\\s*[^\\x00-\\x7F]+\\s*|\\s*[^\\x00-\\x7F]+\\s*$\", \"\", text)\n",
    "                text = re.sub(rf\"\\s*[^\\x00-\\x7F]+\\s*\", \" \", text)\n",
    "            else:\n",
    "                print(f'Excluding image not containing text {image_path}')\n",
    "                return None  \n",
    "            return text\n",
    "    except Exception:\n",
    "        print(f'Error reading {image_path}')\n",
    "        return None\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "df = pd.read_csv('OnToxMeme_dataset/OnToxMeme_annotations.csv')\n",
    "image_folder = 'OnToxMeme_dataset/combined_images/'\n",
    "df_filtered = df[df['symbol_id'].map(df['symbol_id'].value_counts()) > 1].copy()\n",
    "df_filtered['labels'] = [[2]] * len(df_filtered)\n",
    "df_filtered.rename(columns={'meme_id': 'id'}, inplace = True)\n",
    "df_filtered = df_filtered[df_filtered['id'].apply(lambda x: isfile(join(image_folder, f'{x}.png')))]\n",
    "df_filtered['img'] = df_filtered['id'].apply(lambda x: f'{x}.png')\n",
    "df_filtered['text'] = df_filtered['img'].apply(lambda x: extract_text(join(image_folder, x)))\n",
    "df_filtered = df_filtered[df_filtered['text'].notnull()]\n",
    "json_output = df_filtered[['id', 'img', 'labels', 'text', 'symbol_id']].to_json(orient='records')\n",
    "pretty_json = json.dumps(json.loads(json_output), indent=2)\n",
    "\n",
    "with open('OnToxMeme_dataset/toxic_symbolism_entries.json', 'w') as f:\n",
    "    f.write(pretty_json)\n",
    "\n",
    "df = pd.read_json(\"OnToxMeme_dataset/harmless_entries.json\")\n",
    "df['text'] = df['img'].apply(lambda x: extract_text(join(image_folder, x)))\n",
    "df = df.drop(columns=[\"caption\"])\n",
    "json_output = df.to_json(orient='records')\n",
    "pretty_json = json.dumps(json.loads(json_output), indent=2)\n",
    "\n",
    "with open(\"OnToxMeme_dataset/harmless_entries.json\", 'w') as f:\n",
    "    f.write(pretty_json)\n",
    "\n",
    "df = pd.read_json(\"OnToxMeme_dataset/unethical_entries.json\")\n",
    "df['text'] = df['img'].apply(lambda x: extract_text(join(image_folder, x)))\n",
    "df = df.drop(columns=[\"caption\"])\n",
    "json_output = df.to_json(orient='records')\n",
    "pretty_json = json.dumps(json.loads(json_output), indent=2)\n",
    "\n",
    "with open(\"OnToxMeme_dataset/unethical_entries.json\", 'w') as f:\n",
    "    f.write(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All json files get combined into one json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "json_files = ['harmless_entries.json', 'unethical_entries.json', 'toxic_symbolism_entries.json']\n",
    "combined_df = pd.concat([pd.read_json(f'OnToxMeme_dataset/{file}') for file in json_files])\n",
    "json_output = combined_df.to_json(orient='records')\n",
    "pretty_json = json.dumps(json.loads(json_output), indent=2)\n",
    "\n",
    "with open('OnToxMeme_dataset/combined_entries.json', 'w') as f:\n",
    "    f.write(pretty_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
